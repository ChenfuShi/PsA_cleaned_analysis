{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# script to annotat GWAS files with the allelic imbalance files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import pybedtools as pbed \n",
    "import subprocess as sub\n",
    "from multiprocessing import Pool\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.stats.multitest\n",
    "import gzip\n",
    "import subprocess\n",
    "import vcf\n",
    "import io\n",
    "import functools\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "base_dir = \"http://bartzabel.ls.manchester.ac.uk/orozcolab/SNP2Mechanism/\"\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_SNPs_all = pd.read_csv(\"../ATAC_allelic_imbalance/.local/results/ATAC_ALL_allelic_imbalance_with_betabinom.csv.gz\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_set(el):\n",
    "    if isinstance(el, list) or isinstance(el, set):\n",
    "        if len(el) > 1:\n",
    "            return \", \".join(str(e) for e in el)\n",
    "        else:\n",
    "            return list(el)[0]\n",
    "    else:\n",
    "        return el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(file, name):\n",
    "    snps_df  = pd.read_csv(file, sep = \"\\t\", header = None)\n",
    "    snps_df.columns = \"chr start end name score\".split()\n",
    "    snps_df[\"loci\"] = snps_df[\"name\"].str.split(\"_\").str[-1]\n",
    "    snps_df[\"snp\"] = snps_df[\"name\"].str.split(\"_\").str[0]\n",
    "    annotated_snps_df_all = snps_df.merge(all_SNPs_all[[\"ID\",\"corrected_p_val_greater\",\"corrected_p_val_less\",\"tot_REF\",\"tot_ALT\",\"ratio\",\"n_pat\",\"TF_remap\",\"TF_JASPAR\",\"ATAC_hic_corr_score\", \"eQTLgen_gene\", \"eQTLgen_symbol\", \"eQTLgen_pval\",\"hsc_genes\", \"tcell_genes\", \"all_genes\",\"svalues_betabinom\"]], \n",
    "                                          left_on = \"snp\", right_on = \"ID\", how = \"left\")\n",
    "    annotated_snps_df_all = annotated_snps_df_all.applymap(convert_set)\n",
    "    annotated_snps_df_all.to_csv(f\"results_allele_specific_snp/{name}_ALL.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81782/3912690093.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annotated_snps_df_all = annotated_snps_df_all.applymap(convert_set)\n",
      "/tmp/ipykernel_81782/3912690093.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annotated_snps_df_all = annotated_snps_df_all.applymap(convert_set)\n",
      "/tmp/ipykernel_81782/3912690093.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annotated_snps_df_all = annotated_snps_df_all.applymap(convert_set)\n",
      "/tmp/ipykernel_81782/3912690093.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annotated_snps_df_all = annotated_snps_df_all.applymap(convert_set)\n",
      "/tmp/ipykernel_81782/3912690093.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annotated_snps_df_all = annotated_snps_df_all.applymap(convert_set)\n",
      "/tmp/ipykernel_81782/3912690093.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  annotated_snps_df_all = annotated_snps_df_all.applymap(convert_set)\n"
     ]
    }
   ],
   "source": [
    "annotate(f\"{base_dir}/other_tracks/GWAS/tsoi2017_LD_0.8_hg38.bed\", \"psoriasis_tsoi2017\")\n",
    "annotate(f\"{base_dir}/other_tracks/GWAS/RAmetagwas_all_hg38.ld.bed\", \"RAmeta\")\n",
    "annotate(f\"{base_dir}/other_tracks/GWAS/PsA_vs_controls_metagwas_significant.ld.hg38.bed\", \"PsA_meta\")\n",
    "annotate(f\"{base_dir}/other_tracks/GWAS/suggestive_snps_hg38_ld.bed\", \"JIA_suggestive\")\n",
    "annotate(f\"{base_dir}/other_tracks/GWAS/JIA_credible_snps_hg38.bed\", \"JIA_credible\")\n",
    "annotate(f\"{base_dir}/other_tracks/GWAS/elena_hg38.ld.bed\", \"SSc_elena\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alternate script that also adds most severe consequence from ensembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_severe_consequences(variants, species='human', max_batch_size=200):\n",
    "    \"\"\"\n",
    "    Function to get the most severe consequence for each variant ID using the Ensembl API.\n",
    "    \n",
    "    :param variants: A list of variant IDs.\n",
    "    :param species: The species to query (default: 'human').\n",
    "    :param max_batch_size: The maximum number of elements per request (default: 200).\n",
    "    :return: A pandas DataFrame with the variant ID and the most severe consequence.\n",
    "    \"\"\"\n",
    "    def process_batch(batch):\n",
    "        data = json.dumps({\"ids\": batch})\n",
    "        response = requests.post(server + ext, headers=headers, data=data)\n",
    "\n",
    "        if not response.ok:\n",
    "            response.raise_for_status()\n",
    "            sys.exit()\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "    server = \"https://rest.ensembl.org\"\n",
    "    ext = f\"/vep/{species}/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\"}\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, len(variants), max_batch_size):\n",
    "        batch = variants[i:i + max_batch_size]\n",
    "        vep_data = process_batch(batch)\n",
    "\n",
    "        for item in vep_data:\n",
    "            if 'id' in item and 'most_severe_consequence' in item:\n",
    "                results.append({\n",
    "                    'snp': item['id'],\n",
    "                    'most_severe_consequence': item['most_severe_consequence']\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(file, name):\n",
    "    snps_df  = pd.read_csv(file, sep = \"\\t\", header = None)\n",
    "    snps_df.columns = \"chr start end name score\".split()\n",
    "    snps_df[\"loci\"] = snps_df[\"name\"].str.split(\"_\").str[-1]\n",
    "    snps_df[\"snp\"] = snps_df[\"name\"].str.split(\"_\").str[0]\n",
    "    annotated_snps_df_all = snps_df.merge(all_SNPs_all[[\"ID\",\"corrected_p_val_greater\",\"corrected_p_val_less\",\"tot_REF\",\"tot_ALT\",\"ratio\",\"n_pat\",\"TF_remap\",\"TF_JASPAR\",\"ATAC_hic_corr_score\", \"eQTLgen_gene\", \"eQTLgen_symbol\", \"eQTLgen_pval\",\"CD4_lowest_allele_specific\",\"CD8_lowest_allele_specific\",\"hsc_genes\", \"tcell_genes\", \"all_genes\"]], \n",
    "                                          left_on = \"snp\", right_on = \"ID\", how = \"left\")\n",
    "    ensembl_effect = get_most_severe_consequences(snps_df[\"snp\"].to_list())\n",
    "    ensembl_effect = ensembl_effect.drop_duplicates(subset = \"snp\")\n",
    "    annotated_snps_df_all = annotated_snps_df_all.merge(ensembl_effect, on = \"snp\", how = \"left\")\n",
    "    annotated_snps_df_all = annotated_snps_df_all.applymap(convert_set)\n",
    "    annotated_snps_df_all.to_csv(f\"{base_dir}/ATAC_allelic_imbalance/results_allele_specific_snp/{name}_ALL_with_consequence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(f\"{base_dir}/metadata/GWAS_files/tsoi2017_LD_0.8_hg38.bed\", \"psoriasis_tsoi2017\")\n",
    "annotate(f\"{base_dir}/metadata/GWAS_files/RAmetagwas_all_hg38.ld.bed\", \"RAmeta\")\n",
    "annotate(f\"{base_dir}/metadata/GWAS_files/PsA_vs_controls_metagwas_significant.ld.hg38.bed\", \"PsA_meta\")\n",
    "annotate(f\"{base_dir}/metadata/GWAS_files/suggestive_snps_hg38_ld.bed\", \"JIA_suggestive\")\n",
    "annotate(f\"{base_dir}/metadata/GWAS_files/JIA_credible_snps_hg38.bed\", \"JIA_credible\")\n",
    "annotate(f\"{base_dir}/metadata/GWAS_files/elena_hg38.ld.bed\", \"SSc_elena\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64bc073de8d24d484ad5b2fece953d20708d91b167b6996d287dfc1cc29e61ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
